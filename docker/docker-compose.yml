version: "3.9"

services:
  fastchat-controller:
    image: fastchat:latest
    ports:
      - "21001:21001"
    entrypoint: ["python3.9", "-m", "fastchat.serve.controller", "--host", "0.0.0.0", "--port", "21001"]
  fastchat-model-worker:
    image: fastchat:latest
    volumes:
      - /mnt/e/workspace/ai/models:/models
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    entrypoint: ["python3.9", "-m", "fastchat.serve.model_worker",  "--model-path", "/models/THUDM/chatglm3-6b", "--worker-address", "http://fastchat-model-worker:21002", "--controller-address", "http://fastchat-controller:21001", "--host", "0.0.0.0", "--port", "21002"]
  fastchat-api-server:
    image: fastchat:latest
    ports:
      - "8000:8000"
    entrypoint: ["python3.9", "-m", "fastchat.serve.openai_api_server", "--controller-address", "http://fastchat-controller:21001", "--host", "0.0.0.0", "--port", "8000"]
  next-web:
    image: yidadaa/chatgpt-next-web
    ports:
      - "3000:3000"
    environment:
      - CODE=chat_zmices
      - OPENAI_API_KEY=
      - BASE_URL=http://fastchat-api-server:8000
      - HIDE_USER_API_KEY=1
      - DISABLE_GPT4=1
      - DISABLE_FAST_LINK=1
      - CUSTOM_MODELS=-all,+chatglm3-6b